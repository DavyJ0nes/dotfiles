return {
	-- "huggingface/llm.nvim",
	-- dependencies = {
	-- 	{
	-- 		"williamboman/mason.nvim",
	-- 		opts = function(_, opts)
	-- 			opts.ensure_installed = opts.ensure_installed or {}
	-- 			vim.list_extend(opts.ensure_installed, { "llm-ls" })
	-- 		end,
	-- 	},
	-- },
	-- opts = {
	-- 	enable_suggestions_on_startup = true,
	-- 	backend = "ollama",
	-- 	model = "codellama:13b",
	-- 	accept_keymap = "<Tab>",
	-- 	dismiss_keymap = "<S-Tab>",
	-- 	url = "http://localhost:11434/api/generate",
	-- 	-- request_body = {
	-- 	-- 	options = {
	-- 	-- 		temperature = 0.2,
	-- 	-- 		top_p = 0.95,
	-- 	-- 	},
	-- 	-- },
	-- 	fim = {
	-- 		enabled = true,
	-- 		prefix = "<PRE> ",
	-- 		middle = " <MID>",
	-- 		suffix = " <SUF>",
	-- 	},
	-- 	tokens_to_clear = { "<EOT>" },
	-- 	context_window = 4096,
	-- 	tokenizer = {
	-- 		repository = "codellama/CodeLlama-13b-hf",
	-- 	},
	-- },
}
